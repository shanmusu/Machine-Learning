{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import csv\n",
    "import unicodecsv as csv\n",
    "from TwitterAPI import TwitterAPI\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key = 'tb9zMiyUJ9UeX6blluI4Wlws8'\n",
    "consumer_secret = 'XlGNdXHj6Rd2LJ2t9LodnCLydvO2kZ4KLoq95VnQRXfuKXDgZn'\n",
    "access_token = '3231404389-56xTceJ255ar5Sj2sQtWuDj8z0grnNedlqOt5AC'\n",
    "access_token_secret = 'qwPAoWezVnfgeQCCaJy03rOQUJG2Z9ZACzVPIjcqu7IKD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_twitter():\n",
    "    \"\"\" Construct an instance of TwitterAPI using the tokens you entered above.\n",
    "    Returns:\n",
    "      An instance of TwitterAPI.     \n",
    "    \"\"\"\n",
    "    consumer_key = 'tb9zMiyUJ9UeX6blluI4Wlws8'\n",
    "    consumer_secret = 'XlGNdXHj6Rd2LJ2t9LodnCLydvO2kZ4KLoq95VnQRXfuKXDgZn'\n",
    "    access_token = '3231404389-56xTceJ255ar5Sj2sQtWuDj8z0grnNedlqOt5AC'\n",
    "    access_token_secret = 'qwPAoWezVnfgeQCCaJy03rOQUJG2Z9ZACzVPIjcqu7IKD'\n",
    "    return TwitterAPI(consumer_key, consumer_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tweets(twitter,hashtags,tweets,since_id):\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "\n",
    "            request = twitter.request('search/tweets',{'q':hashtags,'count':1000,'lang':'en','max_id':since_id})\n",
    "            for response in request:\n",
    "                tweets.append(response)\n",
    "            print (len(tweets))\n",
    "            return tweets\n",
    "        except:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            break     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_friends(screen_name): \n",
    "    return sorted([friend_id for friend_id in twitter.request('friends/ids',{'screen_name' : screen_name, 'count' :5000})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def select_required(tweet):\n",
    "    data = []\n",
    "    \n",
    "    for each_tweet in tweet:\n",
    "        tweet_data = {}\n",
    "        tweet_data['screen_name']=each_tweet['user']['screen_name']\n",
    "        tweet_data['userid']= each_tweet['user']['id']\n",
    "        tweet_data['description']=each_tweet['user']['description']\n",
    "        tweet_data['tweet']=each_tweet['text']\n",
    "        tweet_data['username']=each_tweet['user']['name']\n",
    "        tweet_data['since_id']=each_tweet['id']\n",
    "        data.append(tweet_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def open_file(tweets,filename):\n",
    "    fname= filename+'.pkl'\n",
    "    p = Path(fname)\n",
    "    if p.is_file():\n",
    "        with open(fname, \"rb\") as file:\n",
    "            try:\n",
    "                tweets = pickle.load(file)\n",
    "            except EOFError:\n",
    "                return tweets\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def write_file(tweets,filename):\n",
    "    fname=filename+'.pkl'\n",
    "    print(\"file length after writing->\",len(tweets))\n",
    "    pickle.dump(tweets, open(fname, 'wb'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Established Twitter connection.\n",
      " started collecting tweets From Twitter Based on location\n",
      "803129723597398016\n",
      "stating\n",
      "length before search  1206\n",
      "100\n",
      "file length after writing-> 1306\n",
      "802644997665386496\n",
      "stating\n",
      "length before search  1246\n",
      "100\n",
      "file length after writing-> 1346\n",
      "801038909488578560\n",
      "stating\n",
      "length before search  1087\n",
      "4\n",
      "file length after writing-> 1091\n",
      "801610462253240321\n",
      "stating\n",
      "length before search  1127\n",
      "100\n",
      "file length after writing-> 1227\n",
      "803404604327268352\n",
      "stating\n",
      "length before search  1138\n",
      "100\n",
      "file length after writing-> 1238\n",
      "803498079278288896\n",
      "stating\n",
      "length before search  793\n",
      "56\n",
      "file length after writing-> 849\n",
      "801586615164473344\n",
      "stating\n",
      "length before search  1129\n",
      "100\n",
      "file length after writing-> 1229\n",
      "tweets saved to a file called tweets \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    twitter = get_twitter()\n",
    "    print('Established Twitter connection.')\n",
    "    print(' started collecting tweets From Twitter Based on location')\n",
    "    hashtags=['#DubNation','#WeTheNorth','#GrindCity','#DetroitBasketball','#thunderup','#LakeShow','#DefendTheLand']\n",
    "    s_id=0\n",
    "    for tags in hashtags:\n",
    "        tweets = []\n",
    "        tweets_from_file =[]\n",
    "        since_id=[]\n",
    "        tweets_from_file =open_file(tweets_from_file,tags)\n",
    "        if tweets_from_file:    \n",
    "            for i in tweets_from_file:\n",
    "                since_id.append(i['since_id'])\n",
    "            s_id=min(since_id)\n",
    "            print (s_id)\n",
    "        print(\"stating\")\n",
    "        print (\"length before search \",len(tweets_from_file))\n",
    "        tweets = get_tweets(twitter,tags,tweets,s_id)\n",
    "        tweets= select_required(tweets)\n",
    "        for i in tweets:\n",
    "            tweets_from_file.append(i)\n",
    "        write_file(tweets_from_file,tags)\n",
    "    print('tweets saved to a file called tweets \\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
